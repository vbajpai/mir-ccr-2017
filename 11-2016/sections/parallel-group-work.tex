%**************************************************************************
\section{Parallel Group Work}\label{sec:parallel-group-work}
%**************************************************************************

The afternoon sessions were used to discuss selected topics in more depth in
smaller groups. This section summarizes the discussions of each group.

% ------------- Andreas Blenk (TUM LKN)
\subsection{SDN/NFV Measurements}

With the introduction of \ac{SDN}, \ac{NV}, and \ac{NFV}, the programmability
and flexibility of our networks is promised to increase. With these new
concepts, networking tasks will be pushed on commodity hardware where they are
programmed as software.  However, this introduces new uncertainties in the
provided performance of these next generation networks as, in particular,
commodity hardware and software are not designed for network processing.
Accordingly, new sophisticated measurement procedures are needed to benchmark
hardware and software components when faced with network packet processing.
Besides, as virtualization introduces an abstraction layer, this might come
with a performance overhead that needs to be considered and quantified. For
this purpose, existing measurement tools, such as MoonGen~\cite{pemmerich:imc:2015}, could be used to evaluate the performance for high
data rate with accurate precision.  Furthermore, tools designed for measuring
non-virtualized and virtualized \ac{SDN} networks (such as \texttt{perfbench}) could
measure the overhead of virtualization components, such as network
hypervisors. Measurements should be conducted on software platforms as well as
real networking testbeds. Hence, testbeds need to be built that include
commodity servers, e.g., making use of accelerated network cards via
\ac{DPDK}, networking functions in software, e.g., functions running in docker
containers, orchestration tools for virtual environments, e.g., HyperFlex~\cite{ablenk:im:2015} and OpenStack, as well as hardware that can generate
realistic network traffic, e.g., Spirent Test Center.  Generally, the
performance evaluation of virtualized networks and SDN networks is an
important task for the design of future communication networks.

% ------------- Georg Carle
\subsection{SDN++: Applications Perspective}

The breakout session entitled SDN++ dealt with SDN from the perspective of how
to apply SDN, and how to introduce improvements to SDN (thereby creating
SDN++), for better meeting the identified requirements.  Participants of the
breakout session were Laurent Vanbever, Artur Hecker, Wolfgang Kellerer,
Edwin Cordeiro and Georg Carle, the latter also being the presenter of the
results.  The method of the working group was first to identify relevant
application areas of SDN, then assess to which extent known SDN approaches
have shortcomings (i.e., identifying the `SDN pain areas'), and subsequently
identifying promising approaches for improving SDN\@.  The application areas of
SDN were (1) establishing means for programmability of the network, which can
be used for improving certain network properties, (2) management of advanced
cellular networks, in particular 5G networks, for different capabilities such
as network slicing, and (3) providing means to add sophisticated control
functionality to corporate networks, such as adding flexible access control.
Identified weaknesses of existing SDN were the fact that existing SDN
southbound interfaces, in particular OpenFlow, operate on a low level of
abstraction, which makes programming of the network time-consuming and error
prone.  Identified areas of improvement and need for further work were
specifying suitable high-level interfaces and abstractions.  There further is
the need to develop tools that are capable of automatically translate
high-level specifications to low-level configuration. A complete tool chain is
required.  This includes measurement tools that are capable of monitoring
changes. Network programmability is beneficial for measurement tools.  It is
expected that SDN management tools will facilitate to deal with the
programmability of networks.  Furthermore, verification tools will allow to
detect and prevent attempts of wrongly programming the network.    These tools
will form a network operating system, with tools that operate on top of the
operating system functions.  Another need for improvement is the development
of a clear transition path from today's networks to future SDN-based networks.
This includes to identify which legacy functionalities from today's networks
we assume being able to depend on in SDN deployments.


% ------------- Lars Eggert
\subsection{QUIC}

QUIC~\cite{draft-ietf-quic-transport} is a new UDP-based reliable transport
protocol with built-in security. The protocol is optimized for HTTP/2~\cite{rfc7540} that is currently being standardized by the \ac{IETF}. QUIC was
originally proposed by Google and has already seen large-scale deployment for
Google services and in Google Chrome. Since September 2016 a new IETF working
group reviews the design of QUIC in order to publish a QUIC protocol
specification with \ac{IETF} consensus. The break out session discussed how
the \ac{IETF} should approach on how the information encrypted in the QUIC
packets might be made available to legitimate network management or firewall
functions. The session also went into retrospect on historical protocol
innovations (such as HIP~\cite{pnikander:comst:2010} and SCTP~\cite{rfc4960})
that failed to get widely deployed to understand whether one needs to be
Google (or a large CDN player) to be able to deploy a protocol on the Internet
today. It was mentioned how good ideas and engineering also needs the right
incentives to see deployment and how partial deployability with one large CDN
player already brings benefits. QUIC is witnessing rapid adoption also because
Google controls both endpoints (browser and servers). As such, two endpoints
that can agree on an exchange that does not require middleware updates makes
it easier to deploy an innovation in practice, but still only influential
organizations have that leverage. Dave Thaler~\cite{draft-iab-protocol-transitions} lays out strategies to allow smooth
transitions of future protocol innovations. Cost and benefit tradeoffs of
simpler deployability and clean-state designs were discussed. The deployment
incentives need to be aligned to allow early adopters to see the investment
benefits. It was also mentioned how operator networks remain opaque to
designers of network protocols and for the need for additional large-scale
measurement initiatives that help bring visibility into how current network
operate in practice would be useful for protocol innovation.

%Brian pointed to TSV area slides.

% Friday notes from Mirja:
% - if deployment incentives are not aligned, it
% - measurement provided by quic. Are additional measurements needed? Only few
%   can do this large-scale measurements. How valuable are measurements of
%   smaller networks (non-google).


% ------------- Johannes Naab / Heiko Niedermayer
\subsection{DDoS Defense beyond Centralization}

The danger of \ac{DDoS} attacks makes web services buy services of a few large
companies, such as Akamai or Cloudflare. Usually, this comes with a loss of
control on the side of the web service over defensive measures, e.g., which
connections are blocked.
Furthermore, we believe that this centralization of the
Internet is threatening the freedom of the Internet as users cannot bypass the
use of services of certain companies anymore. They lose their authority to
select the ones they want to use. In order to overcome this problem, we propose to
make \ac{DDoS} protection a service of ISPs to web services and in further
steps between ISPs and IXPs. If a web service is in trouble it can alarm its
ISP and can influence connections blocked by the ISP on its behalf. Details
need further research.

% ------------- Alexander von Gernler
\subsection{Security}

The security breakout session covered civil liberties and privacy. Firstly,
the group set its focus and decided not to discuss the topics of trustworthy
hardware or civil liberties, but instead to concentrate on \ac{SDN} security
and problems of cloudification. Key results: 1) Customer networks are
converging:  Customers want less own hardware, and want to be more independent
and to lease remote services and equipment rather than owning it.  2)
Virtualization (which happens when you cloudify applications) amplifies known
problems in traditional fields like security, trust, verifiability or
visibility.  3) A special challenge is the cloudification of services that
already utilize virtualization in the traditional model, for example sandboxes
that analyze malware.  For a cloud case, one would end up with nested
virtualization, which in turn comes with even new problems concerning
performance and visibility of the virtualization to the malware being
inspected. 4) Encryption of data still leads to the usability of cloud
scenarios being reduced to mostly SaaS, because homomorphic encryption is
still not there to solve these problems. 5) Special problems with end-to-end
security, e.g., there is more end-to-end encryption happening, which is good.
As a downside however, it makes life harder for people inspecting traffic in
the middle if termination of encrypted connections is done in the cloud, there
will be an unencrypted last mile as new security issue arising from this
scenario.

% ------------- Aaron
\subsection{IoT and ICN}

The breakout session on Internet of Things (IoT) and Information Centric
Networking (ICN) covered the open problems and research directions for
applying ICN technique to IoT. The identified problems include: 1) Limitation
of existing protocols such as Constrained Application Protocol (CoAP) that
handles poorly the frequent leaving/joining events in the network. 2) The
stereotype of ``IoT gateway design'' has hindered novel design. 3) We still
have not yet come up with a suitable Internet architecture that integrates
IoT coherently.

The group discussed how to bring ICN schemes to IoT, and highlighted several
open questions: 1) Where does the network end nowadays? This question couples
with the ICN where nodes can contribute to the computation/content along
the path. 2) What functions on gateway functions we can remove? 3) How to do
naming ``translation'' without changing name/label? 4) Can we do packet
processing while it is passing through queue? 5) How to avoid looping in
the network functions? This is a key concern since we need to keep a
boundary for resource usage in the network. 6) How to maintain the state on
the constrained nodes?

Regarding potential research directions, the group deem the following items
important: 1) Design of end-to-end naming scheme, to facilitate IoT
application composition and bring down the overhead of porting applications
for the cloud to ``gateways''. 2) Semantics for individual sensor and
equivalence group. 3) Trade accuracy with replication. 4) A new computation
abstract suitable for IoT. 5) Abstract of distributed registry for network
function. 6) Rethink how we distribute computing and content.
